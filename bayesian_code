library(tidyverse)
library(lrgs)
library(fastDummies)
library(ggplot2)
library(GGally)
library(HDInterval)

db <- read_csv(choose.files())
db <- db %>% mutate(Species = as.factor(Species))

db <- dummy_cols(db, remove_first_dummy = TRUE,remove_selected_columns = TRUE)

#Verificando váriaveis
boxplot(db$Weight)

#retirando observacao 0
db <- db %>% filter(Weight != 0)

boxplot(db$Length1)
boxplot(db$Length2)
boxplot(db$Length3)
boxplot(db$Height)
boxplot(db$Width)

#verificando correlação entre preditoras
ggpairs(db[,1:6])

#decidimos manter apenas um length

db <- db %>% select(-Length2,-Length3)

ggpairs(db[,1:4])

#dada as claras correlções entre entre as preditoras, adicionamos interação para controlar.

db <- db %>% mutate("Length1:Height" = Length1*Height, "Length1:Width" = Length1*Width, "Height:Width" = Height*Width, "Length1:Height:Width" = Length1*Height*Width)

#tranformando Y para ln(Y)

db <- db %>% mutate(Weight = log(Weight))

#Amostrando dois modelos com valores iniciais diferentes
start_1 <- list(B = matrix(rep(0,14), nrow = 14), Sigma = matrix(1))
start_2 <- list(B = matrix(rep(100,14), nrow = 14), Sigma = matrix(10))

bayesian_model_a <- Gibbs.regression(as.matrix(db[,2:14]), db$Weight, NULL, 10100, trace='bs', fix='xy', start = start_1) ##GIBBS
bayesian_model_b <- Gibbs.regression(as.matrix(db[,2:14]), db$Weight, NULL, 10100, trace='bs', fix='xy', start = start_2)

post_chains_1 <- Gibbs.post2dataframe(bayesian_model_a)[,1:15]
post_chains_2 <- Gibbs.post2dataframe(bayesian_model_b)[,1:15]

colnames(post_chains_1) <- c(paste("B0",1:9, sep = ""),paste("B",10:14, sep=""),"Sigma")


#Verificação gráfica da convergência e calculo das estisticas R

  #plots
for(i in 1:15){
  plot(1:10100,post_chains_1[,i],type = "l", col = 2)
  lines(1:10100,post_chains_2[,i],type = "l", col = 4)
}

  # burn-in

post_chains_1 <- post_chains_1[101:10100,]
post_chains_2 <- post_chains_2[101:10100,]

  #R

r_statistics <- data.frame(colnames(post_chains_1), rep(0,15))
colnames(r_statistics) <- c("Parametro","R")

for (i in 1:15){
  theta_a_i. <- mean(post_chains_1[,i])
  theta_b_i. <- mean(post_chains_2[,i])
  theta_i. <- c(theta_a_i.,theta_b_i.)
  
  theta_i.. <- mean(theta_i.)
  
  B_i <- nrow(post_chains_1)/(length(theta_i.)-1)*sum((theta_i.- theta_i..)^2)
  W_i <- 1/length(theta_i.) * sum(var(c(post_chains_1[,i],post_chains_1[,i])))
  V_i <- (nrow(post_chains_1)-1)/nrow(post_chains_1)*W_i + 1/nrow(post_chains_1)*B_i
  R_i <- sqrt(V_i/W_i)
  
  r_statistics[i,2] <- R_i
}

r_statistics

#distribuicões dos B e Sigma a posteriori

for (i in 1:14){
  g <- ggplot(post_chains_1, aes(x = post_chains_1[,i]))+
    geom_density(fill = 4, color = 4)+
    geom_vline(aes(xintercept = mean(post_chains_1[,i]), color = "Média"), show.legend = TRUE)+
    labs(title = paste("Distribuição a posteriori de B",i),x = paste("B",i), y = "densidade")+
    scale_colour_discrete(name = "Legenda")
    
  print(g)
  #importar para onde precisar
}

ggplot(post_chains_1,aes(x = Sigma))+
  geom_density(fill = 4, color = 4)+
  geom_vline(aes(xintercept = mean(Sigma), color = "Média"),show.legend = TRUE)+
  labs(title = "Distribuição a posteriori de Sigma",x = "Sigma", y = "densidade")+
  scale_colour_discrete(name = "Legenda")


#Intervalos de credibilidade de 95%

cred_intervals <- data.frame(colnames(post_chains_1), rep(0,15), rep(0,15))
colnames(cred_intervals) <- c("Parâmetro","2.5%","97.5%")

for (i in 1:15){
  HPD_region <- HDInterval::hdi(post_chains_1[,i])
  cred_intervals[i,2] <- HPD_region[1]
  cred_intervals[i,3] <- HPD_region[2]
}
# Temos como não significativo algumas dummies de espécie, porém optamos por manter a categórica

#plot dos intervalos

ggplot(cred_intervals, aes(x = "Parâmetro"))+
  geom_segment(aes(x=`Parâmetro`,y = `2.5%`, yend = `97.5%`), color = ifelse(cred_intervals$`2.5%`*cred_intervals$`97.5%`<0,2,4))+
  geom_hline(yintercept = 0, color = 2)+
  coord_flip()

#cálculo da distribuição de r^2 a posteriori

X <- as.matrix(mutate(db, intercepto = 1) %>% select(intercepto, 2:14))
Y <- as.matrix(db[,1])
Y_mean <- mean(Y)

R2_post_distrib <- c()
for (i in 1:10000){
  B <- matrix(as.numeric(post_chains_1[i,1:14]), nrow = 14)
  fitted_values <- X %*% B
  SQE <- sum((Y - fitted_values)^2)
  SQReg <- sum((fitted_values - Y_mean)^2)
  SQT <- SQE + SQReg
  R2 <- SQReg/SQT
  
  R2_post_distrib <- c(R2_post_distrib, R2)
}

ggplot(as.data.frame(R2_post_distrib),aes(x = R2_post_distrib))+
  geom_histogram(aes(y=..density..), bins =50, fill = 4)+
  geom_density(color = 2, fill = 2, alpha = 0.6)+
  geom_vline(aes(xintercept = mean(R2_post_distrib), color = "Média"), show.legend = TRUE)+
  labs(title = "Distribuição a posteriori de R^2",x = "R^2", y = "densidade")+
  scale_colour_discrete(name = "Legenda")

# análise de resíduos pelos betas médios

post_means_B <- rep(0,14)
for (i in 1:14){
  post_means_B[i] <- mean(post_chains_1[,i])
}


fitted_values <- X %*% matrix(post_means_B, nrow = 14)


residuals <- Y - fitted_values
colnames(residuals) <- "residuo"

data.frame(fitted =fitted_values, residuals) %>% ggplot(aes(x = fitted, y = residuo))+
  geom_point()+
  geom_smooth(method = "lm")

ggplot(residuals,aes(x = residuals[,1]))+
  geom_histogram()

ggplot(residuals,aes(sample = residuals[,1]))+
  geom_qq()+
  geom_qq_line()
#os gráficos aparentam normalidade, e detectamos a presença de alguns possíveis outliers

# distribuição preditiva de alguns betas (pode ser uma validação cruzada se quisermos)
# ...
# ..

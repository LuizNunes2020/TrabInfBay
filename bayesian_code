library(tidyverse)
library(lrgs)
library(fastDummies)
library(ggplot2)
library(GGally)
library(HDInterval)

db <- read_csv(choose.files())

db <- db %>% mutate(Species = as.factor(Species))

#Análise descritiva

aux_db <- pivot_longer(db,3:7,names_to = "medida")

ggplot(aux_db,aes(y = value, color = medida))+
  geom_boxplot()+
  theme_minimal()

ggplot(db, aes(y = db$Weight))+
  geom_boxplot(color = 4)+
  coord_cartesian(xlim = c(-1.5,1.5))+
  theme_minimal()

summary(db$Weight)
#retirando observacao 0
db <- db %>% filter(Weight != 0)

#Criando Dummies
db <- dummy_cols(db, remove_first_dummy = TRUE,remove_selected_columns = TRUE)

#verificando correlação entre preditoras
ggpairs(db[,1:6])

#decidimos manter apenas um length

db <- db %>% select(-Length2,-Length3)

ggpairs(db[,1:3])

#dada as claras correlações entre entre as preditoras, adicionamos interação para controlar.

db <- db %>% mutate("Length1:Height" = Length1*Height, "Length1:Width" = Length1*Width, "Height:Width" = Height*Width, "Length1:Height:Width" = Length1*Height*Width)

#tranformando Y para ln(Y)

db <- db %>% mutate(Weight = log(Weight))

#Amostrando dois modelos com valores iniciais diferentes

n <- 10100 # número de iterações das cadeias
p <- 13 # número de covariaveis

start_1 <- list(B = matrix(rep(0,p+1), nrow = p+1), Sigma = matrix(1))
start_2 <- list(B = matrix(rep(100,p+1), nrow = p+1), Sigma = matrix(10))

bayesian_model_a <- Gibbs.regression(as.matrix(db[,2:(p+1)]), db$Weight, NULL, n, trace='bs', fix='xy', start = start_1) ##GIBBS
bayesian_model_b <- Gibbs.regression(as.matrix(db[,2:(p+1)]), db$Weight, NULL, n, trace='bs', fix='xy', start = start_2)

post_chains_1 <- Gibbs.post2dataframe(bayesian_model_a)
post_chains_2 <- Gibbs.post2dataframe(bayesian_model_b)

colnames(post_chains_1) <- c(paste("B",0:(p), sep = ""),"Sigma")


#Verificação gráfica da convergência e calculo das estisticas R

#plots

#betas
for(i in 1:(p+1)){
  media_i <- mean(post_chains_1[100:n,i])
  dp_i <- sd(post_chains_1[100:n,i])
  
  g <- ggplot(NULL, aes(x = 1:n))+
    geom_step(data = post_chains_1, mapping = aes(y = post_chains_1[,i]), color = 2)+
    geom_step(data = post_chains_2, mapping = aes(y = post_chains_2[,i]), color = 4)+
    coord_cartesian(ylim = c(media_i - 8*dp_i, media_i+8*dp_i))+
    labs(title = paste("Iterações de B",i-1," em duas cadeias diferentes", sep = ""), x = "Iterações", y = paste("B",i-1,sep = ""))+
    theme_minimal()
  
  print(g)
}

#Sigma
ggplot(NULL, aes(x = 1:n))+
  geom_step(data = post_chains_1, mapping = aes(y = post_chains_1[,p+2]), color = 2)+
  geom_step(data = post_chains_2, mapping = aes(y = post_chains_2[,p+2]), color = 4)+
  coord_cartesian(ylim = c(0,0.15))+
  labs(title = "Iterações de Sigma em duas cadeias diferentes", x = "Iterações", y = "Sigma")+
  theme_minimal()

# burn-in

post_chains_1 <- post_chains_1[101:10100,]
post_chains_2 <- post_chains_2[101:10100,]

n<- 10000

#R

r_statistics <- data.frame(colnames(post_chains_1), rep(0,p+2))
colnames(r_statistics) <- c("Parametro","R")

for (i in 1:(p+2)){
  theta_a_i. <- mean(post_chains_1[,i])
  theta_b_i. <- mean(post_chains_2[,i])
  theta_i. <- c(theta_a_i.,theta_b_i.)
  
  theta_i.. <- mean(theta_i.)
  
  B_i <- nrow(post_chains_1)/(length(theta_i.)-1)*sum((theta_i.- theta_i..)^2)
  W_i <- 1/length(theta_i.) * sum(var(c(post_chains_1[,i],post_chains_1[,i])))
  V_i <- (nrow(post_chains_1)-1)/nrow(post_chains_1)*W_i + 1/nrow(post_chains_1)*B_i
  R_i <- sqrt(V_i/W_i)
  
  r_statistics[i,2] <- R_i
}

r_statistics

#distribuicões dos B e Sigma a posteriori

for (i in 1:p+1){
  g <- ggplot(post_chains_1, aes(x = post_chains_1[,i]))+
    geom_density(fill = 4, color = 4)+
    geom_vline(aes(xintercept = mean(post_chains_1[,i]), color = "Média"),linetype = "longdash", show.legend = TRUE)+
    labs(title = paste("Distribuição a posteriori de B",i),x = paste("B",i), y = "densidade")+
    scale_colour_discrete(name = "Legenda")+
    theme_minimal()
  
  print(g)
  #importar para onde precisar
}

ggplot(post_chains_1,aes(x = Sigma))+
  geom_density(fill = 4, color = 4)+
  geom_vline(aes(xintercept = mean(Sigma), color = "Média"),linetype = "longdash",show.legend = TRUE)+
  labs(title = "Distribuição a posteriori de Sigma",x = "Sigma", y = "densidade")+
  scale_colour_discrete(name = "Legenda")+
  theme_minimal()


#Intervalos de credibilidade de 95%

cred_intervals <- data.frame(colnames(post_chains_1), rep(0,p+2), rep(0,p+2))
colnames(cred_intervals) <- c("Parâmetro","2.5%","97.5%")

for (i in 1:(p+2)){
  HPD_region <- HDInterval::hdi(post_chains_1[,i])
  cred_intervals[i,2] <- HPD_region[1]
  cred_intervals[i,3] <- HPD_region[2]
}
# Temos como não significativo algumas dummies de espécie, porém optamos por manter a categórica

#plot dos intervalos

ggplot(cred_intervals, aes(x = "Parâmetro"))+
  geom_segment(aes(x=`Parâmetro`,y = `2.5%`, yend = `97.5%`), color = ifelse(cred_intervals$`2.5%`*cred_intervals$`97.5%`<0,2,4))+
  geom_hline(yintercept = 0, color = 2, linetype = "longdash")+
  coord_flip()

#cálculo da distribuição de r^2 a posteriori

X <- as.matrix(mutate(db, intercepto = 1) %>% select(intercepto, 1:p+1))
Y <- as.matrix(db[,1])
Y_mean <- mean(Y)


R2_post_distrib <- c()
for (i in 1:n){
  B <- matrix(as.numeric(post_chains_1[i,1:(p+1)]), nrow = p+1)
  fitted_values <- X %*% B
  SQE <- sum((Y - fitted_values)^2)
  SQReg <- sum((fitted_values - Y_mean)^2)
  SQT <- SQE + SQReg
  R2 <- SQReg/SQT
  
  R2_post_distrib <- c(R2_post_distrib, R2)
}

ggplot(as.data.frame(R2_post_distrib),aes(x = R2_post_distrib))+
  geom_density(color = 4, fill = 4)+
  geom_vline(aes(xintercept = mean(R2_post_distrib), color = "Média"), linetype  = "longdash",show.legend = TRUE)+
  labs(title = "Distribuição a posteriori de R^2",x = "R^2", y = "densidade")+
  scale_colour_discrete(name = "Legenda")+
  theme_minimal()

# análise de resíduos pelos betas médios

post_means_B <- rep(0,p+1)
for (i in 1:(p+1)){
  post_means_B[i] <- mean(post_chains_1[,i])
}


fitted_values <- X %*% matrix(post_means_B, nrow = p+1)


residuals <- Y - fitted_values
colnames(residuals) <- "residuo"

data.frame(fitted =fitted_values, residuals) %>% ggplot(aes(x = fitted, y = residuo))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_minimal()

ggplot(residuals,aes(x = residuals[,1]))+
  geom_histogram()+
  theme_minimal()

ggplot(residuals,aes(sample = residuals[,1]))+
  geom_qq()+
  geom_qq_line()+
  theme_minimal()
#os gráficos aparentam normalidade, e detectamos a presença de alguns possíveis outliers

# distribuição preditiva de alguns betas (pode ser uma validação cruzada se quisermos)
# ...
# ..
